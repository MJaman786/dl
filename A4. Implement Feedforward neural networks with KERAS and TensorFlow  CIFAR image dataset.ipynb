{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2b30a304-3f7e-4d9d-aa97-7f02ce61e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "78bfb85f-9e40-4af1-8df1-a9323b7c5a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'datasets/4_CIFAR 10_images_dataset/cifar10_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12b6f186-049e-43dd-8a92-1dfbb73166b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_generator = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=True,\n",
    "    rescale=1/255.0,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "47d79865-0619-45be-b724-097a25903c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48000 images belonging to 10 classes.\n",
      "Found 12000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = dataset_generator.flow_from_directory(\n",
    "    dataset,\n",
    "    target_size=(32, 32),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "test_data = dataset_generator.flow_from_directory(\n",
    "    dataset,\n",
    "    target_size=(32, 32),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b46c208b-f8d2-4841-b96e-892d67accc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 2, 2, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,202\n",
      "Trainable params: 160,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e7158db9-6ca6-48e0-9ae2-fea0f8136c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ea8a3079-13b6-42e0-8844-cadd80b54281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.8807 - accuracy: 0.7008 - val_loss: 0.8833 - val_accuracy: 0.6975\n",
      "Epoch 2/100\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.8814 - accuracy: 0.7015 - val_loss: 0.9076 - val_accuracy: 0.6892\n",
      "Epoch 3/100\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.8804 - accuracy: 0.7023 - val_loss: 0.8471 - val_accuracy: 0.7097\n",
      "Epoch 4/100\n",
      "1500/1500 [==============================] - 48s 32ms/step - loss: 0.8826 - accuracy: 0.7020 - val_loss: 0.8712 - val_accuracy: 0.7057\n",
      "Epoch 5/100\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.8818 - accuracy: 0.7031 - val_loss: 0.8889 - val_accuracy: 0.6985\n",
      "Epoch 6/100\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.8720 - accuracy: 0.6999 - val_loss: 0.8903 - val_accuracy: 0.6919\n",
      "Epoch 7/100\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.8733 - accuracy: 0.7051 - val_loss: 0.8654 - val_accuracy: 0.7053\n",
      "Epoch 8/100\n",
      "1500/1500 [==============================] - 46s 30ms/step - loss: 0.8790 - accuracy: 0.7025 - val_loss: 0.8614 - val_accuracy: 0.7039\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Can also be 'val_accuracy'\n",
    "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restores model weights from the epoch with the best value of the monitored quantity\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=(len(train_data)),\n",
    "    epochs=100,\n",
    "    validation_data=(test_data),\n",
    "    validation_steps=(len(test_data)),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "03c5d346-34ce-4b8f-9b60-b9f65ac866f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 9s 25ms/step - loss: 0.8374 - accuracy: 0.7109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8373835682868958, 0.7109166383743286]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "87a173af-4219-48fb-b41b-3786ab456cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck'\n",
    "]\n",
    "\n",
    "\n",
    "def load_image_process(image_path):\n",
    "    image = load_img(image_path, target_size=(32,32,3))\n",
    "    image_arr = img_to_array(image)\n",
    "    image_arr = image_arr / 255.0\n",
    "    image_arr = image_arr.reshape(1,32,32,3)\n",
    "    return image_arr\n",
    "\n",
    "def process_display(image_path):\n",
    "    processed_image = load_image_process(image_path)\n",
    "    prediction = model.predict(processed_image)\n",
    "\n",
    "    index = np.argmax(prediction)\n",
    "    class_label = labels[index]\n",
    "\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.title(f'prediction : {class_label}')\n",
    "    plt.imshow(load_img(image_path, target_size=(32,32,3)))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8b8e1424-2ba1-4b2c-8330-e5e0c7d817bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = 'datasets/4_CIFAR 10_images_dataset/cifar10_dataset/0/image_0.png' #plane\n",
    "# image = 'datasets/4_CIFAR 10_images_dataset/cifar10_dataset/1/image_1.png' #automobile\n",
    "# image = 'datasets/4_CIFAR 10_images_dataset/cifar10_dataset/2/image_2.png' #bird\n",
    "# image = 'datasets/4_CIFAR 10_images_dataset/cifar10_dataset/3/image_3.png' #cat--  \n",
    "# image = 'datasets/4_CIFAR 10_images_dataset/cifar10_dataset/4/image_4.png' #deer---\n",
    "# image = 'datasets/4_CIFAR 10_images_dataset/cifar10_dataset/5/image_5.png' #dog--\n",
    "# image = 'datasets/4_CIFAR 10_images_dataset/cifar10_dataset/6/image_6.png' #frog\n",
    "# image = 'datasets/4_CIFAR 10_images_dataset/cifar10_dataset/7/image_7.png' #horse\n",
    "# image = 'datasets/4_CIFAR 10_images_dataset/cifar10_dataset/8/image_8.png' #ship\n",
    "# image = 'datasets/4_CIFAR 10_images_dataset/cifar10_dataset/9/image_9.png' #truck\n",
    "process_display(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
